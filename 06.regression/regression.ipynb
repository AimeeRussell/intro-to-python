{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2503666d-e65c-483f-9133-92e9e8bc43e2",
   "metadata": {},
   "source": [
    "# linear regression with python\n",
    "\n",
    "In this exercise, we'll see how we can use python for both simple and linear regression. We'll also see how we can calculate the correlation between two variables, and get some additional practice working with grouped data.\n",
    "\n",
    "## data\n",
    "\n",
    "The data used in this exercise are the historic meteorological observations from the [Armagh Observatory](https://www.metoffice.gov.uk/weather/learn-about/how-forecasts-are-made/observations/recording-observations-for-over-100-years) (1853-present), the Oxford Observatory (1853-present), the Southampton Observatory (1855-2000), and Stornoway Airport (1873-present), downloaded from the [UK Met Office](https://www.metoffice.gov.uk/research/climate/maps-and-data/historic-station-data) that we used in previous exercises.\n",
    "\n",
    "## getting started\n",
    "\n",
    "First, we'll import the various packages that we will be using here:\n",
    "\n",
    "- [pandas](https://pandas.pydata.org/), for reading the data from a file;\n",
    "- [seaborn](https://seaborn.pydata.org/), for plotting the data;\n",
    "- [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html), for calculating correlation coefficients;\n",
    "- [statsmodels.api](https://www.statsmodels.org/dev/index.html), for linear regression;\n",
    "- [pathlib](https://docs.python.org/3/library/pathlib.html), for working with filesystem paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309c34f-0b08-408d-ab41-fcbe1d8f489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d9b2c-f3ed-4ebd-9e9d-07dd014d07ac",
   "metadata": {},
   "source": [
    "Next, we'll use `pd.read_csv()` to load the combined station data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab381e-9a51-4f51-ae00-e797e4bc88fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = pd.read_csv(Path('data', 'combined_stations.csv'), parse_dates=['date']) # load the combined station data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d370d-c0e2-45dd-83db-21a8a90930ea",
   "metadata": {},
   "source": [
    "## plotting relationships\n",
    "\n",
    "Before jumping into correlation and regreesion, let's have a look at the data we're investigating. In the cell below, write some lines of code to create a scatter plot of `tmax` vs `rain`, with different colors, shapes, and a regression line for each season. Be sure to assign the plot to an object called `rain_tmax_plot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995e5f56-a6c4-4a19-8b57-75bd6567b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here!\n",
    "rain_tmax_plot # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca300fa-e003-4fe7-ae6c-995356dbb6bc",
   "metadata": {},
   "source": [
    "What kind of relationship is there between `tmax` and `rain`? Does it depend on the season? How strong is the relationship, and what does this mean for the slope of each regression line?\n",
    "\n",
    "## calculating correlation\n",
    "\n",
    "The next thing we'll look at is how to calculate the *correlation* between two variables, using a few different methods. We'll start by calculating the covariance for all values of a variable in a **DataFrame**, then we'll have a look at calculating correlation using `scipy.stats` ([documentation](https://docs.scipy.org/doc/scipy/reference/stats.html)).\n",
    "\n",
    "### using pandas .corr()\n",
    "\n",
    "The basic use of `corr()` ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html)) calculates Pearson's correlation coefficient between each column in the table, pairwise. With the `method` argument, we can also calculate Spearman's rho (`method='spearman'`) and Kendall's tau (`method='kendall'`).\n",
    "\n",
    "Because we have non-numeric variables in the table, we'll use the `numeric_only` argument to avoid a `ValueError` being raised. Helpfully, `.corr()` ignores any `NaN` values for us, so we don't have to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74209fa4-830d-464d-a291-9a05b4182256",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data.corr(numeric_only=True) # calculate the correlation between all numeric variables in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8575115-565e-46c3-b330-59c936f6e863",
   "metadata": {},
   "source": [
    "Out of all of the variables in the table, which have the strongest correlation (ignoring the values on the diagonal)? Does this make sense?\n",
    "\n",
    "### by groups\n",
    "\n",
    "We're more interested in calculating the correlation for different groups - as you can see from the plot above, the relationship between `rain` and `tmax` is not the same in each season - even though the overall correlation is slightly negative, the correlation in winter is clearly positive.\n",
    "\n",
    "We've already seen all of the different parts we need here. To calculate the correlation based on `season`, we can use `.groupby()` to group the dataset before calling `.corr()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94679517-6b54-4a0f-a5a1-d7d318a3f939",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data.groupby('season')[['rain', 'tmax']].corr() # calculate pearson's r for rain and tmax, grouped by season"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d40845-773e-4b0e-bfc5-60e81aad2f1b",
   "metadata": {},
   "source": [
    "### using scipy.stats\n",
    "\n",
    "From the outputs above, you can see that `pandas.DataFrame.corr()` outputs the full covariance matrix, not just the correlation value we're interested in. In the cells below, we'll see how we can use some of what we have learned previously, along with `scipy.stats`, to create a **DataFrame** with just the correlation values between `rain` and `tmax`.\n",
    "\n",
    "In the cell below, we'll use a `for` loop to calculate correlation coefficients (Pearson's r, Spearman's rho, and Kendall's tau) for `rain` and `tmax` based on data from each season. We'll build a nested list of the correlation coefficients for each season by first creating an empty list, then using `list.append()` to add the coefficients for each season in turn.\n",
    "\n",
    "Before running the cell, be sure to create an object, `seasons`, that contains the names of each season. You can write this explicitly, but you might want to practice getting this output from the data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97502e50-89c6-48e9-97e2-b62aba5425c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of season names - remember that there's more than one way to do this!\n",
    "corr_data = [] # initalize an empty list\n",
    "\n",
    "for season in seasons:\n",
    "    season_data = station_data.loc[station_data['season'] == season].dropna(subset=['rain', 'tmax']) # select the data for this season, drop nan values from rain and tmax\n",
    "    this_corr = [stats.pearsonr(season_data['rain'], season_data['tmax']).statistic, # calculate pearson's r between rain and tmax\n",
    "                 stats.spearmanr(season_data['rain'], season_data['tmax']).statistic, # calculate spearman's rho between rain and tmax\n",
    "                 stats.kendalltau(season_data['rain'], season_data['tmax']).statistic] # calculate kendall's tau between rain and tmax\n",
    "    corr_data.append(this_corr) # add these values to the list\n",
    "\n",
    "corr_data # show the nested list of correlation values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c2da9c-68ba-425a-bcbb-33f6baf4e164",
   "metadata": {},
   "source": [
    "Now that we have created the nested list (effectively, an array of values), we can create a new **DataFrame** object by specifying the `data`, `index`, and `columns` arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f90dd7-76f3-4af3-bc09-c6c203e42579",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.DataFrame(data=corr_data, index=seasons, columns=['pearson', 'spearman', 'kendall']) # create a dataframe with the correlation data\n",
    "corr_df # show the correlation dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6381fd10-c7e1-4480-abf8-2c3deed89209",
   "metadata": {},
   "source": [
    "Note that calculating the correlation coefficient using `scipy.stats` has an additional benefit - unlike with `pandas.DataFrame.corr()`, `scipy.stats` will also provide a significance value for the calculated correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde6fea-e1b6-475e-8adb-a8e91e713177",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = stats.pearsonr(station_data.dropna(subset=['rain', 'tmax'])['rain'], \n",
    "                      station_data.dropna(subset=['rain', 'tmax'])['tmax'])\n",
    "\n",
    "print(f\"calculated value of r: {corr.statistic:.3f}\")\n",
    "print(f\"calculated p-value of r: {corr.pvalue}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318a6171-4a05-4136-93d0-196a5eff85e8",
   "metadata": {},
   "source": [
    "## simple linear regression\n",
    "\n",
    "We'll start by fitting a linear model for spring. To prepare the data, write a line of code below that selects only the spring observations, and assigns the output to an object called `spring`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bdb409-6519-467c-94e1-c5e618e5e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only spring observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c284858-4364-4b83-ad24-d17f94926812",
   "metadata": {},
   "source": [
    "Remember that a linear model with a single variable has the form:\n",
    "\n",
    "$$ y = \\beta + \\alpha x, $$\n",
    "\n",
    "where $\\beta$ is the intercept and $\\alpha$ is the slope of the line. To fit a linear model using ordinary least squares, we can first use `sm.OLS()`  ([documentation](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html)) to create an **OLS** object, then use the `.fit()` method ([documentation](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.fit.html)) of that object.\n",
    "\n",
    "When we create the **OLS** object, we pass the observations of the *response* (*dependent*) variable with the first argument, and the observations of the *explanatory* (*independent*) variable(s) in the second argument. Note that by default, **OLS** will not fit a constant, but we can use `sm.add_constant()` ([documentation](https://www.statsmodels.org/dev/generated/statsmodels.tools.tools.add_constant.html)) to add a column of ones to the array.\n",
    "\n",
    "So, the process to fit a linear relationship between `tmax` and `rain` would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e5f5f2-6788-4d5b-a85a-fff79b0b8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = station_data.dropna(subset=['rain', 'tmax'])['rain'] # select the rain variable, after dropping NaN values\n",
    "ydata = station_data.dropna(subset=['rain', 'tmax'])['tmax'] # select the tmax variable, after dropping NaN values\n",
    "\n",
    "xdata = sm.add_constant(xdata) # add a constant to xdata - otherwise, we're only fitting the slope\n",
    "\n",
    "lin_model = sm.OLS(ydata, xdata) # initialize the OLS object\n",
    "lm_results = lin_model.fit() # fit the model to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda01e81-8b28-45d9-9324-0f6f45b0b395",
   "metadata": {},
   "source": [
    "The `params` attribute has the estimated values for the intercept (`const`) and slope (`rain`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18194d-37c8-4672-abd4-80661309c135",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_results.params # see the regression parameters: const is the intercept, rain is the coefficient for 'rain'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106f89d-bf97-409d-90c3-22f21d70235e",
   "metadata": {},
   "source": [
    "Other useful attributes include:\n",
    "\n",
    "- `bse`, the estimates of the standard error for the parameters;\n",
    "- `pvalues`, the two-tailed *p*-values for the *t*-statistics of the parameter estimates;\n",
    "- `resid`, the model residuals;\n",
    "- `rsquared` and `rsquared_adj`, the R-squared and adjusted R-squared values for the model.\n",
    "\n",
    "Note that each of these attributes are **pandas.Series**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b2c1e-350c-4201-973e-eb26f64260c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(lm_results.bse) # show the type of lm_results.bse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6e076d-a45d-4887-bbd8-6636035c992d",
   "metadata": {},
   "source": [
    "This means that we can easily combine these into a **DataFrame** using `pd.concat()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc83cfc-3f20-4e86-9ed2-b8c0621c2430",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.concat([lm_results.params, lm_results.bse, lm_results.tvalues, lm_results.pvalues, lm_results.conf_int()], axis=1) # join params, bse, tvalues, pvalues, confidence intervals along the column axis\n",
    "res_df.columns = ['coef', 'std err', 't-value', 'p-value', 'ci_low', 'ci_up'] # set the column names\n",
    "\n",
    "res_df # show the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debcd1ce-377f-4690-a237-4d392f6cbbb9",
   "metadata": {},
   "source": [
    "To get the full summary of the regression results, use `.summary()` ([documentation](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.RegressionResults.summary.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b5879d-8162-404e-a03a-344914cde420",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_results.summary() # show the summary of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed86c6dc-ace9-4c3a-81c3-fe8457b03e2a",
   "metadata": {},
   "source": [
    "## multiple linear regression\n",
    "\n",
    "Now, let's try to fit a linear model of `tmax` with two variables: `rain` and `sun`. Remember that multiple linear regression tries to fit a model with the form:\n",
    "\n",
    "$$ y = \\beta + \\alpha_1 x_1 + \\cdots + \\alpha_n x_n $$\n",
    "\n",
    "With only two variables, this would look like:\n",
    "\n",
    "$$ y = \\beta + \\alpha_1 x_1 + \\alpha_2 x_2 $$\n",
    "\n",
    "The code to fit this model using `statsmodels` looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b73e5e-27cd-4e81-b253-1adf1ed81167",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = station_data.dropna(subset=['rain', 'tmax', 'sun'])[['rain', 'sun']] # select the rain and sun variables, after dropping NaN values\n",
    "ydata = station_data.dropna(subset=['rain', 'tmax', 'sun'])['tmax'] # select the tmax variable, after dropping NaN values\n",
    "\n",
    "xdata = sm.add_constant(xdata) # add a constant to xdata - otherwise, we're only fitting the slope\n",
    "\n",
    "ml_model = sm.OLS(ydata, xdata) # initialize the OLS object\n",
    "mlm_results = ml_model.fit() # fit the model to the data\n",
    "\n",
    "mlm_results.params # see the regression parameters: const is the intercept, rain is the coefficient for 'rain'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43f2037-dd88-4f8d-baa6-f65cfd08e6ef",
   "metadata": {},
   "source": [
    "Just as with the simple linear regression case, we can look at the summary of the regression results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385af31-d0b5-42ab-b80d-0b1175f71a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_results.summary() # show the summary of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861dc26d-3493-410d-a9c1-c976982a2f75",
   "metadata": {},
   "source": [
    "## bonus: linear regression with groups\n",
    "\n",
    "As a final exercise, let's see how we can combine some of the tools we've used in the workshop so far, along with a few new ones, to fit linear models for each season.\n",
    "\n",
    "For the most part, the structure of this is the same as the correlation example previously. We loop over each season name, and add the result to some variable - in this case, a **dict**, where the keys are the names of each season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90e49e-8ea2-471c-9f39-4e42da252b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict() # initialize an empty dictionary\n",
    "\n",
    "for season in seasons:\n",
    "    season_data = station_data.loc[station_data['season'] == season].dropna(subset=['rain', 'tmax']) # select the data for this season, drop nan values from rain and tmax\n",
    "\n",
    "    xdata = season_data['rain'] # select the rain variable\n",
    "    ydata = season_data['tmax'] # select the tmax variable\n",
    "    \n",
    "    xdata = sm.add_constant(xdata) # add a constant to xdata - otherwise, we're only fitting the slope\n",
    "    \n",
    "    model = sm.OLS(ydata, xdata) # initialize the OLS object\n",
    "    results[season] = model.fit() # add the result to the results dict, with season as the key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a679b-659e-4c17-968a-5af57a596fd9",
   "metadata": {},
   "source": [
    "Now, we can view the model summary for each season by using the season name as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79779f5d-9b90-48cc-9b90-4e017b96570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['spring'].summary() # view the summary for spring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a971a-fc7d-458c-b2ea-9053ab907980",
   "metadata": {},
   "source": [
    "Next, let's see how we can combine these results into a single **DataFrame**. First, we'll write a **function** to create the **DataFrame** for a single model result - as we have discussed, it is often preferable to write functions for repeated lines of code, as it can make the code more readable, it helps avoid mistakes, and also because programmers are often lazy.\n",
    "\n",
    "Run the next cell to define the function - the only new bits of code here are the use of `.reset_index()` ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html)), which will turn the current index parameter names into a column, `index`, and the use of `.rename()` to rename this column from `index` to `parameter`. The reason for doing this will be clear in a moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4311d9a-afdf-4d14-9baf-fdefb3441e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(res):\n",
    "    res_df = pd.concat([res.params, res.bse, res.tvalues, res.pvalues, res.conf_int()], axis=1) # join params, bse, tvalues, pvalues, confidence intervals along the column axis\n",
    "    res_df.columns = ['coef', 'std err', 't-value', 'p-value', 'ci_low', 'ci_up'] # set the column names\n",
    "    res_df.reset_index(inplace=True) # unset the index in-place\n",
    "    \n",
    "    return res_df.rename(columns={'index': 'parameter'}) # return the dataframe with 'index' renamed to 'parameter'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0940c-1166-462c-add0-c207e43591ae",
   "metadata": {},
   "source": [
    "Now, we can loop over the season names to get the parameter table for each season, then use `pd.concat()` to combine these results into a single **DataFrame**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7545bfd8-7804-4ea6-a472-ce4c5d810017",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for season in seasons:\n",
    "    this_df = get_results_df(results[season]) # get a dataframe for this season\n",
    "    this_df['season'] = season\n",
    "    all_results.append(this_df)\n",
    "\n",
    "all_results = pd.concat(all_results) # combine the list of dataframes into a single dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cecabb-0683-48aa-9efd-4843720c78c3",
   "metadata": {},
   "source": [
    "Finally, we'll use `.set_index()` ([documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html)) to set the index of the **DataFrame** using the `season` and `parameter` columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b2c26-98a2-4b4f-aa8b-cf6efd8ef29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.set_index(['season', 'parameter'], inplace=True) # set a multi-level index with season and parameter values\n",
    "all_results # show the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f66b7d-7960-46cc-962c-cb8880c15d08",
   "metadata": {},
   "source": [
    "Now, in the final **DataFrame**, we can use the season name with `.loc` to get the parameter results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36faa97-80a7-4a9e-9b53-2ba559aa8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.loc['spring'] # show the rows of the dataframe corresponding to spring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaffe66-ab7c-4f22-8943-6c179ca914ce",
   "metadata": {},
   "source": [
    "and, save the table of regression parameter results to a file, using `pd.to_csv()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35bf961-2e27-4a2e-8718-646551949204",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.to_csv(Path('data', 'regression_results.csv')) # save the results to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc6d47-415a-4bf9-badd-30a76adf7fea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## exercise and next steps\n",
    "\n",
    "That's all for this exercise, and for the exercises of this workshop. The next sessions are BYOD (\"bring your own data\") sessions where you can start building your **git** project repository by applying the different concepts and skills that we have covered in the workshop. Before then, if you would like to practice these skills further, try at least one of the following suggestions:\n",
    "\n",
    "- Investigate the relationship between `tmax` and `sun` overall, and by individual seasons, using `pandas.DataFrame.corr()`. What kind of relationship do these variables appear to have?\n",
    "- What is the relationship between `tmin` and `sun`? does it change by season?\n",
    "- Set up and fit a multiple linear regression model for `air_frost` as a function of `tmax`, `tmin`, `sun`, and `rain` in the winter. Which of these variables has the strongest effect on `air_frost` (hint: )?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
